

<aside class="info"><div class="info-inner"><p>The <em>invisible UI</em> paradigm is developing rapidly, so this story will evolve in time with the latest innovations, commentaries and controversies.</p></div></aside>

<h3><a name="Should_Developers_And_Designers_Really_Seek_to_Make_UI_Invisible">Should Developers And Designers Really Seek to Make UI Invisible?</a></h3>

<p>Google <em>design invisible</em>, read a few of the posts, and you’ll find dozens of designers agreeing that the best design is nearly always invisible. (The contrapositive is also popular, we really notice bad design.) The argument runs thus: A great product should be designed so that it just works, and the considerable time and effort taken to make it work perfectly shouldn't be obvious to the user.</p>

<p>It's an attractive idea which, taken to extremes, can lead technologists to pursue what's commonly called a <em>No UI</em> interface, where content is central and everything else--controls, notifications, processes--are somehow unnoticeable.</p>

<p>But is the <em>best</em> UI the one that's least perceptible? And if so, is it always the case?</p>

<h3><a name="What_This_Story_Is_Tracking">What This Story Is Tracking:</a></h3>

<p>Zero-interface designs are creeping into phones, desktops, tablets, cars and televisions. New ideas about UI could lead to use-cases for technology that we've never conceived of--or it could lead to a generation of impossibly confusing, arcane devices. We hash out the opinions here and cite products and designs we think will change the conversation.</p>

<hr />

<h2><a name="Updates">Updates</a></h2>

<p><strong>One of the ideals ascribed to future interfaces: That they should feel like <em>magic</em>.</strong> The things a user has to do to control an action should be so fluid and natural that it's almost like the device itself knows what they want to do in advance. David Holz (CEO of Leap Motion, perhaps one of the most exciting <em>spatial interface</em> devices coming on sale), phrased this more eloquently when he spoke recently at SXSW. Via <a href="http://www.guardian.co.uk/media-network/media-network-blog/2013/apr/03/wearable-technology-machine-to-machine" target="_blank">The Guardian</a>:</p>

<blockquote><p>This world [of natural gestural interfaces] perceives you in new ways. It is very much a new reality, when you reach out for an object using leap motion, it comes to you--it's like being a Jedi.</p></blockquote>

<p>Leap Motion's hardware and software can read user's hand gestures so well it's being experimented on for projects from controlling a remote controlled boat to making an air harp musical instrument; check out these stories from <a href="http://www.newscientist.com/blogs/onepercent/2013/04/hand-waving-leap-hack-drives-a-toy-boat-with-gestures.html?cmpid=rss%7cnsns%7c2012-global%7conline-news" target="_blank">New Scientist</a> and  <a href="http://www.engadget.com/2013/04/13/airbeats-airharp/" target="_blank">Engadget</a>.</p>

<p>But one of the most compelling demonstrations has come from a surprising source: NASA. On stage at the recent Game Developers Conference, scientists remotely controlled the one-ton Athlete rover prototype using Leap Motion. Far from being a simple demo of a more intuitive way to command a rover on a distant planet or moon, NASA sees this sort of spatial UI as key to near future robotic exploration of our solar system--because the interface is so transparent it helps the operator feel like they're actually <em>tele-present</em>. Whether or not a spatial UI is as beneficial here on Earth remains to be seen. Via <a href="http://www.theverge.com/2013/3/27/4154900/nasa-athlete-leap-motion-gdc" target="_blank">The Verge</a>.</p>

<hr />

<p><strong></strong>A different kind of invisible UI is the subject of a recent patent award to Apple.[/b] In this case, actually invisible. US <a href="http://patft.uspto.gov/netacgi/nph-parser?sect1=pto1&amp;amp;sect2=hitoff&amp;amp;d=pall&amp;amp;p=1&amp;amp;u=%2fnetahtml%2fpto%2fsrchnum.htm&amp;amp;r=1&amp;amp;f=g&amp;amp;l=50&amp;amp;s1=8,407,623.pn.&amp;amp;os=pn/8,407,623&amp;amp;rs=pn/8,407,623" target="_blank">patent number 8,407,623</a> concerns "playback control using a touch interface," but it's not related to Apple's numerous other touchscreen patents. Instead Apple has considered how you may be able to meaningfully interact with a touchscreen device like an iPhone when you can't see its display because it's in a pocket or bag. The specific idea is to:</p>

<blockquote><p>Control media playback using a touch sensing device without requiring the selection of displayed options...</p></blockquote>

<p>This is actually more sophisticated than it may appear--even the most advanced touchscreen UIs rely on visual feedback to let you know when you've touched or gestured on the right part of the display. To manage this, Apple's patent makes mention of controls like single, double taps or even circular dialing motions on the touchscreen which could control volume.</p>

<p>Of course gestures like these, made furtively under the dinner table or on an iPod strapped to a runner's arm, could be confusing without visual feedback. Hence sections of the patent mention the device giving audible or tactile notice that a gesture has been correctly recognized:</p>

<blockquote><p>Wherein the tactile feedback comprises at least one vibration that matches a touch pattern of the detected touch gesture.</p></blockquote>

<p>You might argue this still constitutes a "user interface," but what Apple's clearly trying to do here is imagine how users could seamlessly interact with their touchscreen device when they can't see the screen. Part of the "No UI" argument is <em>what actually qualifies</em> as UI-less and what's merely a less-immersive, traditional interface.</p>

<hr />

<p><strong>Not touching the screen of a touchscreen phone may seem odd.</strong> But that's the core feature of the <a href="https://www.getsensus.com" target="_blank">upcoming Sensus iPhone case</a>. It's a protective plastic case with multitouch sensors built into the sides and back that work a lot like the built-in ones on the phone's screen, and it plugs into the iPhone's data port to transmit its control signals. The whole thing may remind you of the rear touchpad on Sony's PS Vita. The idea is to actively add to the touch experience by making use of where the user's hands naturally fall when holding the device; developers can use the case's controls to interact with their apps through some straightforward API hooks. Wired, which <a href="http://www.wired.com/gadgetlab/2013/01/ces-2013-sensus-iphone-case/" target="_blank">tested one at CES</a>, described the experience like this:</p>

<blockquote><p>When reading, for example, or browsing the internet, you can navigate without swiping your finger across the screen. Simply run your fingers along the edge, or over the back. It's almost magical.<br />
</p></blockquote>

<hr />

<p><strong>Apple's known for the tactile beauty of its devices, but what about jewelery?</strong> Apple is no stranger to non-touch interactions--just look at Siri. But a recent twist to the long-standing Apple TV rumors include <a href="http://www.fastcompany.com/3007802/tech-forecast/apple-television-rumors-have-new-ring" target="_self">mention of a new interface device</a>: the "iRing." Analyst brian white of Topeka Capital Markets had spoken to sources inside Apple's supply chain and suggested that as part of its plan to "revolutionize the TV experience forever" would include a spatial UI controller that fits around the user's finger. Via <a href="http://appleinsider.com/articles/13/04/03/rumor-apple-television-with-iring-motion-controller-to-launch-this-year" target="_blank">AppleInsider</a>.</p>

<blockquote><p>The "iRing" accessory described by White is a new concept that has not been previously detailed in other reports. His visits with Apple suppliers suggested the ring will act as a "navigation pointer" for the television, and will allow the TV set to enhance motion detection and replace some of the functionality found in a remote.</p></blockquote>

<p>We can guess that if it exists the iRing would likely use a short-range low-power wireless connection like Bluetooth 4 because of its small scale. We can also guess that it would include some form of motion-sensor and perhaps a signalling light, akin to Sony's Play Motion Control system for its Playstation 3. This could give the device extremely accurate motion-sensing powers for subtle gestures--perhaps at finger-sized scales--that could lead to some powerful applications. Would the "iRing" also be a remote microphone for a Siri-enabled voice control interface too? This could be the ultimate hands-off, zero-interface way to interact with your TV. But would it work for a desktop or mobile device?</p>

<hr />

<p><strong>Siri, perhaps the ultimate "no-UI" interface you can use today, may soon have a rival</strong>: Amazon is said to have paid some $26 million to buy Evi, a very Siri-like voice recognizer personal digital assistant. (via <a href="http://techcrunch.com/2013/04/17/sources-say-amazon-acquired-siri-like-evi-app-for-26m-is-a-smartphone-coming/" target="_blank">TechCrunch</a>)</p>

<p>Evi, from British startup True Knowledge, uses the same Nuance technology that Apple's said to use for Siri and worked on both iOS and Android. It was initially under threat from Apple for being too similar to Siri, but was ultimately allowed to remain available. If anything Evi sounds a little more advanced than Siri currently is, perhaps representing what Siri may become soon, because TechCrunch notes it:</p>

<blockquote><p>has been described as being capable of ‘learning’. It has an ontology of tens of thousands of classes and almost a billion ‘facts’ (machine understandable bits of knowledge) and, says True Knowledge, can infer trillions more when needed</p></blockquote>

<p>Amazon's goal for Evi is unknown, but the service could easily find a home on Kindle Fire devices to both boost their overall functionality and add utility for users with disabilities. The move has sparked speculation, of course, that Amazon is going to release a smartphone--as has <a href="http://www.fastcompany.com/3001079/fast-take-amazons-smartphone" target="_self">long been rumored</a>. Evi on a smartphone would help Amazon rival Apple, and if it leveraged Amazon's extensive cloud infrastructure and tapped into the company's content cloud (as would seem inevitable) then it could be a very powerful content discovery/recommendations engine. Evi could also move Amazon still <a href="http://www.fastcompany.com/1824943/google-siriously-nervous-about-search-innovations" target="_self">further away from Google</a> infrastructure in its forked edition of Android.</p>

<p>Separately <a href="http://www.fastcompany.com/most-innovative-companies/2013/apple" target="_self">Apple</a>, for its own part, seems to be beginning a concerted push to advance Siri's functionality and importance within iOS. <a href="http://www.fastcompany.com/3007670/tech-forecast/apple-gets-siri-ous-posts-12-siri-related-job-openings" target="_self">Recent job offerings</a>, numbering well about 10 individual positions, suggest that the company is trying to rapidly grow the team. Since iOS 7 is well under <a href="http://news.softpedia.com/news/Apple-Testing-iOS-7-on-New-iPhone-Model-345674.shtml" target="_blank">development</a>, this would make for perfect timing.</p>

<hr />

<p><strong>There's a Kickstarter rival for Leap that's open, not closed</strong>. DUO is a <a href="http://createdigitalmotion.com/2013/04/duo-is-a-diy-3d-sensor-like-leap-but-open-source-from-gesture-and-vision-veterans/" target="_blank">home-brew 3D gesture sensor project</a> that's seeking $100,000 in cash through <a href="http://www.kickstarter.com/projects/codelabs/duo-the-worlds-first-diy-3d-sensor" target="_blank">crowdfunding site Kickstarter</a>. Unlike Leap Motion the basic premise of DUO is that the hardware and software systems that make it work will be open source. The hope seems to be that this will make DUO ripe for some really clever, innovative hacking that could quickly deliver some truly next-generation UI interactions.</p>

<p>DUO uses a twin camera system, much like Leap, and though its VGA resolution seems crude it can scan the 3-D area in front of the cameras (and thus sense user's hand positions and gestures) up to 374 times a second. The level of sensing accuracy this could create is significant--enabling the sort of gestural finesse needed to play a virtual musical instrument and perform fast, detailed moves for gameplay.</p>

<p>Hackers have already <a href="http://www.fastcompany.com/1744069/zoolander-meets-dr-evil-kinect-hack-prints-out-model-mini-you" target="_self">leveraged</a> Microsoft's <a href="http://www.fastcompany.com/1771025/kinect-hacked-3-d-scanning-archaeology-site" target="_self">Kinect platform</a> (which DUO is intended to out-perform) for all sorts of incredibly novel uses. Hence DUO's Kickstarter page suggests the kit would be useful for</p>

<blockquote><p>Art/Visualizations <br />
Human Computer Interaction <br />
Gaming/Entertainment <br />
Robotics/Machine Vision <br />
3D Scanning/Environment Mapping </p></blockquote>

<p>It's a bold vision, and seems targeted at the developer and maker community versus Leap's evidently more commercial goals.</p>

<figure class="inline-video inline"><iframe src="http://www.youtube.com/embed/U180f3XG20o?rel=1&amp;autoplay=0" width="631" height="380" frameborder="0"></iframe></figure>

<hr />

<p><em>Image: by Flickr user <a href="http://www.flickr.com/seeminglee" target="_blank">seeminglee</a></em></p>