

<aside class="info"><div class="info-inner"><p>The "invisible UI" paradigm is developing rapidly, so this story will evolve in time with the latest innovations, commentaries and controversies.</p></div></aside>

<h3><a name="Can_it_really_be_true_that_the_best_interface_is_no_interface_at_all">Can it really be true that the best interface is no interface at all?</a></h3>

<p>Google the words "design invisible" and you'll find plenty of blog posts that arguing that good design is nearly always invisible. The argument runs thus: a great product should be designed so that it just works, and the considerable time and effort taken to make it work like this shouldn't be obvious to the user. It's an attractive idea which, taken to extremes, can lead technologists to pursue what's commonly called a "No UI" interface, where content is central and everything else--controls, notifications, processes--are somehow obscured. The big question: Is the "best" UI the one that's least perceptible?</p>

<h3><a name="What_this_story_is_tracking">What this story is tracking:</a></h3>

<p>Zero-interface designs are creeping into phones, desktops, tablets, cars and televisions. New ideas about UI could lead to use-cases for technology that we've never conceived of--or it could lead to a generation of impossibly confusing, arcane devices. We hash out the opinions here and cite products and designs we think will change the conversation.</p>

<hr />

<h2><a name="Updates">Updates</a></h2>

<p><strong>One of the dreams of future ui tech is that using it should almost feel like magic.</strong> The things a user has to do to control an action should be so fluid and natural that it's almost like the device itself knows what they want to do in advance. David Holz (CEO of Leap Motion, perhaps one of the most exciting "spatial interface" devices coming on sale), phrased this more eloquently when he spoke recently at SXSW. Via <a href="http://www.guardian.co.uk/media-network/media-network-blog/2013/apr/03/wearable-technology-machine-to-machine" target="_blank">The Guardian</a>:</p>

<blockquote><p>This world [of natural gestural interfaces] perceives you in new ways. It is very much a new reality, when you reach out for an object using leap motion, it comes to you--it's like being a Jedi.</p></blockquote>

<p>Leap Motion's hardware and software can read user's hand gestures so well it's being experimented on for projects from controlling a remote controlled boat to making an air harp musical instrument; check out these stories from <a href="http://www.newscientist.com/blogs/onepercent/2013/04/hand-waving-leap-hack-drives-a-toy-boat-with-gestures.html?cmpid=rss%7cnsns%7c2012-global%7conline-news" target="_blank">New Scientist</a> and  <a href="http://www.engadget.com/2013/04/13/airbeats-airharp/" target="_blank">Engadget</a>. But one of the most compelling demonstrations has come from a surprising source: NASA. On stage at the recent Game Developers Conference, scientists remotely controlled the one-ton Athlete rover prototype using Leap Motion. Far from being a simple demo of a more intuitive way to command a rover on a distant planet or moon, NASA sees this sort of spatial UI as key to near future robotic exploration of our solar system--because the interface is so transparent it helps the operator feel like they're actually "tele-present". Whether or not a spatial UI is as beneficial here on Earth remains to be seen. Via <a href="http://www.theverge.com/2013/3/27/4154900/nasa-athlete-leap-motion-gdc" target="_blank">The Verge</a>.</p>

<hr />

<p><strong></strong>A different kind of invisible UI is the subject of a recent patent award to Apple.[/b] In this case, actually invisible. US <a href="http://patft.uspto.gov/netacgi/nph-parser?sect1=pto1&amp;amp;sect2=hitoff&amp;amp;d=pall&amp;amp;p=1&amp;amp;u=%2fnetahtml%2fpto%2fsrchnum.htm&amp;amp;r=1&amp;amp;f=g&amp;amp;l=50&amp;amp;s1=8,407,623.pn.&amp;amp;os=pn/8,407,623&amp;amp;rs=pn/8,407,623" target="_blank">patent number 8,407,623</a> concerns "playback control using a touch interface," but it's not related to Apple's numerous other touchscreen patents. Instead Apple has considered how you may be able to meaningfully interact with a touchscreen device like an iPhone when you can't see its display because it's in a pocket or bag. The specific idea is to:</p>

<blockquote><p>Control media playback using a touch sensing device without requiring the selection of displayed options...</p></blockquote>

<p>This is actually more sophisticated than it may appear--even the most advanced touchscreen UIs rely on visual feedback to let you know when you've touched or gestured on the right part of the display. To manage this, Apple's patent makes mention of controls like single, double taps or even circular dialing motions on the touchscreen which could control volume.</p>

<p>Of course gestures like these, made furtively under the dinner table or on an iPod strapped to a runner's arm, could be confusing without visual feedback. Hence sections of the patent mention the device giving audible or tactile notice that a gesture has been correctly recognized:</p>

<blockquote><p>Wherein the tactile feedback comprises at least one vibration that matches a touch pattern of the detected touch gesture.</p></blockquote>

<p>You might argue this still constitutes a "user interface," but what Apple's clearly trying to do here is imagine how users could seamlessly interact with their touchscreen device when they can't see the screen. Part of the "No UI" argument is <em>what actually qualifies</em> as UI-less and what's merely a less-immersive, traditional interface.</p>

<hr />

<p><strong>Not touching the screen of a touchscreen phone may seem odd.</strong> But that's the core feature of the <a href="https://www.getsensus.com" target="_blank">upcoming Sensus iPhone case</a>. It's a protective plastic case with multitouch sensors built into the sides and back that work a lot like the built-in ones on the phone's screen, and it plugs into the iPhone's data port to transmit its control signals. The whole thing may remind you of the rear touchpad on Sony's PS Vita. The idea is to actively add to the touch experience by making use of where the user's hands naturally fall when holding the device; developers can use the case's controls to interact with their apps through some straightforward API hooks. Wired, which <a href="http://www.wired.com/gadgetlab/2013/01/ces-2013-sensus-iphone-case/" target="_blank">tested one at CES</a>, described the experience like this:</p>

<blockquote><p>When reading, for example, or browsing the internet, you can navigate without swiping your finger across the screen. Simply run your fingers along the edge, or over the back. It's almost magical.<br />
</p></blockquote>

<hr />

<p><strong>Apple's known for the tactile beauty of its devices, but what about jewelery?</strong> Apple is no stranger to non-touch interactions--just look at Siri. But a recent twist to the long-standing Apple TV rumors include <a href="http://www.fastcompany.com/3007802/tech-forecast/apple-television-rumors-have-new-ring" target="_self">mention of a new interface device</a>: the "iRing." Analyst brian white of Topeka Capital Markets had spoken to sources inside Apple's supply chain and suggested that as part of its plan to "revolutionize the TV experience forever" would include a spatial UI controller that fits around the user's finger. Via <a href="http://appleinsider.com/articles/13/04/03/rumor-apple-television-with-iring-motion-controller-to-launch-this-year" target="_blank">AppleInsider</a>.</p>

<blockquote><p>The "iRing" accessory described by White is a new concept that has not been previously detailed in other reports. His visits with Apple suppliers suggested the ring will act as a "navigation pointer" for the television, and will allow the TV set to enhance motion detection and replace some of the functionality found in a remote.</p></blockquote>

<p>We can guess that if it exists the iRing would likely use a short-range low-power wireless connection like Bluetooth 4 because of its small scale. We can also guess that it would include some form of motion-sensor and perhaps a signalling light, akin to Sony's Play Motion Control system for its Playstation 3. This could give the device extremely accurate motion-sensing powers for subtle gestures--perhaps at finger-sized scales--that could lead to some powerful applications. Would the "iRing" also be a remote microphone for a Siri-enabled voice control interface too? This could be the ultimate hands-off, zero-interface way to interact with your TV. But would it work for a desktop or mobile device?</p>

<hr />

<p><em>Image: by Flickr user <a href="http://www.flickr.com/seeminglee" target="_blank">seeminglee</a></em></p>