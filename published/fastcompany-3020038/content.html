<p>Digital goods are increasingly being <a href="http://www.fastcolabs.com/3016158/if-you-want-to-sell-digital-products-bundle-them-with-physical-ones" target="_self">bundled with physical goods</a> to make them easier to merchandise. FastCo.Labs brought together three designers at the NYC-based creative agency <a href="http://www.codeandtheory.com/" target="_blank">Code and Theory</a> to discuss what makes an integrated user experience worthwhile. Here they explore why the convergence of digital and physical products--from smart TVs to newspapers--has prompted a need for a smarter approach to multidisciplinary design.</p>

<p><strong>Dan Gardner, Co-founder &amp; Executive Creative Director UX:</strong> So, the whole point of why we’re debating physical and digital design is because we feel like each represents one thing. But both invoke a feeling. Both invoke an emotional response.</p>

<p><strong>Mike Treff, Managing Partner of the Product Design Group:</strong> I actually concur, but I also think there’s definitional issues with this title. I don’t think it’s about what came first. It’s more about: When did the duality between physical and digital actually start to actually matter?</p>

<p><strong>Gardner:</strong> Look at TVs. Today, you can do more than just browse content. So this discussion is more about understanding how products with physical and digital components--like TVs--are starting to evolve into a much more interactive and meaningful experience.</p>

<p><strong>Geoff Baldwin, Lead Industrial Designer:</strong> When you think of digital interaction, you generally think of something on a screen. What’s so ironic about the lack of successful TV interaction design is that at its core, TV is just a giant screen. So the question becomes: <em>Why</em> is the interaction design on TV so poor, and <em>why</em> is the physical hardware design so poor?</p>

<p><strong>Treff:</strong> Historically, the TV experience was purely consumptive: up, up, down, down to get to the content you wanted to see. As the TV experience became more interactive, and included experience elements like On Demand, Pay Per View and second screen interactions, the industry’s response was to solve most interaction problems with hardware solutions. So now you’ve got a lack of congruity between the hardware and the interaction design that the hardware is meant to manipulate and display.</p>

<p><strong>Baldwin:</strong> Right. Every time you added a feature to the content, you needed another button on the remote to keep up with the UI.</p>

<p><strong>Gardner:</strong> Well, you didn’t <em>need</em> it. That’s just what happened.</p>

<p><strong>Baldwin:</strong> Yeah, it’s what happened. So now, it’s gotten to the point where you have a million buttons on a remote. Thankfully, the digital interface is starting to catch up with the physical interaction. Designers now have the opportunity to completely rethink what a remote control is and what a digital entertainment experience <em>should</em> be.</p>

<p><strong>Treff:</strong> So the question becomes: At what point does the interplay between the digital and the physical become critical to the product experience?</p>

<p><strong>Gardner:</strong> I think it started with the fact that we have different types of screens for every single situation we’re in. However, the user expects a consistent experience across all screens. How I hold and interact with the physical object that surrounds the screen—that expectation is becoming a blurred line.</p>

<p><strong>Baldwin:</strong> It’s funny. It used to be that we designed products and worried about what the logo looked like on the physical product. Now, the physical product is becoming the talisman for the digital experience.</p>

<p><strong>Gardner:</strong> If the experience is the identity, then part of that experience is the screen, and part of it is the physical object. I think people are still slow to catch on to this.</p>

<p><strong>Baldwin:</strong> Yeah. It is weird. Look at the history of branding: Your brand used to be a mark. Then, it became a product. Now, branding is all about how people <em>use</em> a product, like Google --</p>

<p><strong>Treff:</strong> Exactly. The verb of “Googling” is the brand.</p>

<p><strong>Gardner:</strong> It also goes back to the purposefulness of good design. If you design with purpose, you will, of course, get an aesthetically-pleasing design. But at the heart of it, you should be solving a usage problem. The design solution has to extend to both physical <em>and</em> digital. It’s one in the same.</p>

<p><strong>Baldwin:</strong> Exactly. One becomes a catalyst for the other. And it’s not always only in one direction.</p>

<p><strong>Treff:</strong> Agree completely. I think this is analogous to newspapers. In the past, when newspapers were just physical products, everything that affected the reading experience was centrally-located: Designers and content creators were all in the newsroom. It was a much more integrated process. The end product had to be done at a certain time, and then it was shipped to a printer.</p>

<p>When newspapers went online, the digital team was siloed away. Then the digital ad team was siloed away. Then the technology team was a thousand miles away. Suddenly, everyone was segmented and there was no person to sit at the locus and make it cohesive on the input side so that it was cohesive on the experience side.</p>

<p><strong>Gardner:</strong> Right. The point is that creativity can’t be limited to one silo. Frankenstein systems don’t really work that well.</p>

<p><strong>Baldwin:</strong> One thing we always say is that design isn’t finished until it’s developed. Sure, you can 3D print anything, or render something in minute, but <em>fulfilling</em> the physical design still takes blood, sweat and tears, just like it always has. You can’t fulfill it with <em>just</em> strategy.</p>

<p><strong>Treff:</strong> So, for physical and digital design--how <em>should</em> the approach be consistent? How should it be different?</p>

<p><strong>Gardner:</strong> In the ideal sense of all design, they should be moving in parallel. You have design and engineering happening at the same time, and you’re learning from both and making decisions along the way.</p>

<p><strong>Treff:</strong> It’s like when we do a tech assessment in the definition phase of a project. We don’t just look at the platform. We look at things like: What are the right tools? What’s the right stack? What’s the right framework? It’s really critical work that happens before we design anything.</p>

<p><strong>Gardner:</strong> Obviously, there’s no perfect solution. Ultimately, the hardware shouldn’t be separate from the digital screen, the digital front-end shouldn’t be separate from the engineering, and the physical hardware shouldn’t be separate from the mechanical engineering.</p>

<p><strong>Baldwin:</strong> Exactly. Design is messy. You can’t be afraid to start at the end. You can’t be afraid to Wes Anderson a project. At the end of the day, you want to do the most efficient amount of trial-and-error as possible. And that doesn’t necessarily mean it’s going to be a linear process. Physical and digital design move on different timelines.</p>

<p><strong>Gardner:</strong> The reality is you need a stimulus. The catalyst has to come from somewhere. It could come from the hardware or the software, but it has to be human. I think in any design process, you can’t be afraid to go back a step. Once you’re afraid to go back, that’s when you have a problem.</p>

<p><strong>Baldwin:</strong> Actually, the car is a great example. Knobs and buttons are designed into the car before the content and user experience is even <em>considered</em>. So, it’s not just figuring out the digital experience, it’s figuring out the user experience: How do I interact with this thing physically, digitally, emotionally?</p>

<p><strong>Gardner:</strong> Right. User experience isn’t digital interaction design. It’s user experience.</p>

<p>Look at the actual physical buttons and knobs--why do you need them? Maybe it’s because you can’t drive a car and look at a screen at the same time. The point is you have to figure out the starting purpose to the design. <em>That’s</em> the user experience.</p>

<p><strong>Baldwin:</strong> Right. I don’t think we should think of a knob as a knob. We should think of it as a connection point to a digital experience. When you stop thinking about a screen as a screen, you can start to think about it as a digital canvas for a physical interaction.</p>

<p><strong>Gardner:</strong> Yes. The output.</p>

<p><strong>Treff:</strong> Physical and digital design should both stem from the user experience. It all needs to be cohesive. Bringing an idea to life in a way that is meaningful and productive is all about reducing complexity and focusing on simplicity.</p>

<p><strong>Gardner:</strong> Right. It’s how you do it, and it goes back to having an integration philosophy. It’s hard enough to define what simplicity is. The process to get there is hard. You need an integrated approach, or else you’ll fail. You see that time and time again.</p>

<p><strong>Baldwin:</strong> I think people mistake integration for doing <em>everything</em>. In reality, integration is about creating focus. It’s about creating products and interactions that have empathy for each other.</p>

<p><strong>Treff:</strong> I love it when you say that. Every time it gets me really warm and fuzzy.</p>

<p><strong>Baldwin:</strong> In the end, great design is when a product knows what it’s good at, the feature knows what it’s used for, and they understand how they fit together.</p>